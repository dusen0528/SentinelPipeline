"""
ë¹„ëª… ê°ì§€ í”„ë¡œì„¸ì„œ

ResNet18 ê¸°ë°˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì—ì„œ ë¹„ëª…ì„ ê°ì§€í•©ë‹ˆë‹¤.
ê¸°ê³„ìŒ í•„í„°ë§ ë° ë¹„ëª… ê°•ë„ ë¶„ì„ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

import os
import gc
import torch
import torch.nn as nn
import torch.nn.functional as F
import librosa
import numpy as np
from typing import Tuple, Any, Optional, Dict
import logging

from sentinel_pipeline.domain.interfaces.audio_processor import AudioProcessor

logger = logging.getLogger(__name__)


class ScreamDetector(AudioProcessor):
    """
    ResNet18 ê¸°ë°˜ ë¹„ëª… ê°ì§€ê¸°
    
    ê¸°ê³„ìŒ í•„í„°ë§ ë° ë¹„ëª… ê°•ë„ ë¶„ì„ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        model_path: str,
        threshold: float = 0.6,
        device: str = "auto",
        model_arch: str = "resnet18",  # "resnet18" (ResNet34 ë ˆê±°ì‹œ ì§€ì› ì œê±°)
        enable_filtering: bool = True,  # í•„í„°ë§ ë¡œì§ í™œì„±í™” ì—¬ë¶€
    ):
        """
        Args:
            model_path: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ (.pth)
            threshold: ë¹„ëª… íŒì • ì„ê³„ê°’ (0.0 ~ 1.0)
            device: ë””ë°”ì´ìŠ¤ ('auto', 'cuda', 'cpu')
            model_arch: ëª¨ë¸ ì•„í‚¤í…ì²˜ ('resnet18')
            enable_filtering: ê¸°ê³„ìŒ í•„í„°ë§ ë° ë¹„ëª… ê°•ë„ ë¶„ì„ í™œì„±í™” ì—¬ë¶€
        """
        self.model_path = model_path
        self.threshold = threshold
        self.enable_filtering = enable_filtering
        
        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        # ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.sample_rate = 16000
        self.window_sec = 2.0
        self.n_fft = 1024
        self.hop_length = 512
        self.n_mels = 64
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ì • (ResNet18ë§Œ ì§€ì›)
        self.model_arch = "resnet18"
        
        
        self.model = self._load_model()
        self.model.eval()
        
        logger.info(
            f"ScreamDetector initialized on {self.device} "
            f"(arch={self.model_arch}, threshold={threshold}, filtering={enable_filtering})"
        )

    def _load_model(self) -> nn.Module:
        """
        ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        
        ResNet-ScreamDetectì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë¡œë“œ:
        1. ImageNet ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”
        2. conv1ì„ 1ì±„ë„ë¡œ ë³€ê²½
        3. fcë¥¼ 2í´ë˜ìŠ¤ë¡œ ë³€ê²½
        4. í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
        """
        try:
            from torchvision import models
            
            # ResNet18 ëª¨ë¸ ë¡œë“œ (ImageNet ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš© - ResNet-ScreamDetectì™€ ë™ì¼)
            # ì°¸ê³ : í•™ìŠµ ì‹œì—ë„ ImageNet ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            try:
                model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
            except (AttributeError, TypeError):
                # êµ¬ë²„ì „ torchvision í˜¸í™˜ì„±
                try:
                    model = models.resnet18(pretrained=True)
                except:
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°€ì¤‘ì¹˜ ì—†ì´ ì´ˆê¸°í™”
                    logger.warning("Could not load ImageNet weights, using random initialization")
                    model = models.resnet18(weights=None)
            
            # 1ì±„ë„(Grayscale) ì…ë ¥ ìˆ˜ìš© (ResNet-ScreamDetectì™€ ë™ì¼)
            model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
            
            # ì¶œë ¥ ë ˆì´ì–´ ì„¤ì • (2ê°œ í´ë˜ìŠ¤: Non-Scream, Scream)
            num_ftrs = model.fc.in_features
            model.fc = nn.Linear(num_ftrs, 2)
            
            if not os.path.exists(self.model_path):
                logger.warning(f"Model file not found at {self.model_path}, using ImageNet weights only")
                return model.to(self.device)
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ (ResNet-ScreamDetectì™€ ì •í™•íˆ ë™ì¼í•œ ë°©ì‹)
            # ì›ë³¸: model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
            try:
                state_dict = torch.load(self.model_path, map_location=self.device, weights_only=False)
                model.load_state_dict(state_dict)
                logger.info(f"Model weights loaded from {self.model_path}")
            except Exception as e:
                logger.error(f"Error loading model weights: {e}")
                logger.warning("Using ImageNet weights only (model file may be corrupted)")
                
            return model.to(self.device)
        except Exception as e:
            logger.error(f"Error loading model architecture: {e}")
            raise

    def _preprocess(self, audio: np.ndarray) -> torch.Tensor:
        """
        ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬: ê¸¸ì´ ë§ì¶¤ -> Mel-Spectrogram -> ì •ê·œí™” -> í…ì„œ
        
        Args:
            audio: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            
        Returns:
            ì „ì²˜ë¦¬ëœ í…ì„œ [1, 1, Height, Width]
        """
        target_len = int(self.sample_rate * self.window_sec)
        
        # ê¸¸ì´ ë§ì¶”ê¸° (íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°)
        if len(audio) < target_len:
            audio = np.pad(audio, (0, target_len - len(audio)), mode='constant', constant_values=0.0)
        else:
            audio = audio[:target_len]
        
        # Mel-Spectrogram ë³€í™˜ (librosa ë°©ì‹ - ResNet18 ëª¨ë¸ê³¼ í˜¸í™˜)
        # ì°¸ëª¨ ì˜ê²¬: í•™ìŠµ ì‹œì™€ í† ì”¨ í•˜ë‚˜ ì•ˆ í‹€ë¦¬ê³  ë˜‘ê°™ì´ ì ìš©í•´ì•¼ í•¨
        melspec = librosa.feature.melspectrogram(
            y=audio, sr=self.sample_rate,
            n_mels=self.n_mels, n_fft=self.n_fft, hop_length=self.hop_length
        )
        melspec_db = librosa.power_to_db(melspec, ref=np.max)
        
        # ì •ê·œí™” (Min-Max Scaling) - í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë°©ì‹
        # ì£¼ì˜: ë§ˆì´í¬ ì…ë ¥ ê°ë„(Gain)ì— ë”°ë¼ RMS ê°’ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ (í•„í„° ì„ê³„ê°’ íŠœë‹ í•„ìš” ê°€ëŠ¥ì„±)
        min_val, max_val = melspec_db.min(), melspec_db.max()
        if max_val - min_val > 0:
            melspec_norm = (melspec_db - min_val) / (max_val - min_val)
        else:
            melspec_norm = melspec_db
        
        # [Batch, Channel, Height, Width] í˜•íƒœë¡œ ë³€í™˜
        tensor = torch.tensor(melspec_norm, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        
        return tensor.to(self.device)
    
    def _is_human_voice(self, segment: np.ndarray) -> Tuple[bool, str]:
        """
        ì‚¬ëŒ ëª©ì†Œë¦¬ì¸ì§€ ê¸°ê³„ìŒì¸ì§€ íŒë³„ (ì œê³µëœ ì½”ë“œì˜ ì •êµí•œ ë²„ì „)
        
        ê¸°ê³„ìŒ(ë¹„í”„ìŒ) íŠ¹ì§•:
        - Spectral Flatnessê°€ ë§¤ìš° ë‚®ìŒ (ë‹¨ì¼ ì£¼íŒŒìˆ˜)
        - Spectral Bandwidthê°€ ë§¤ìš° ì¢ìŒ
        - Zero-Crossing Rateê°€ ë§¤ìš° ê·œì¹™ì 
        - Pitch ë³€í™”ê°€ ê±°ì˜ ì—†ìŒ
        
        Args:
            segment: ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸
            
        Returns:
            (is_human, reason) íŠœí”Œ
        """
        if len(segment) < self.sample_rate * 0.1:
            return True, "ë„ˆë¬´ ì§§ìŒ"
        
        #ë¬´ìŒ ì²´í¬ (0 ë‚˜ëˆ„ê¸° ì—ëŸ¬ ë°©ì§€)
        if np.max(np.abs(segment)) < 0.001:
            return False, "ë¬´ìŒ"
        
        try:
            # 1. Spectral Flatness (0ì— ê°€ê¹Œìš°ë©´ í†¤ì„±, 1ì— ê°€ê¹Œìš°ë©´ ë…¸ì´ì¦ˆ)
            flatness = librosa.feature.spectral_flatness(y=segment)[0]
            mean_flatness = np.mean(flatness)
            
            # 2. Spectral Bandwidth (ì£¼íŒŒìˆ˜ í­)
            bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=self.sample_rate)[0]
            mean_bandwidth = np.mean(bandwidth)
            
            # 3. Spectral Centroid ë³€í™”ëŸ‰ (í”¼ì¹˜ ë³€í™”)
            centroid = librosa.feature.spectral_centroid(y=segment, sr=self.sample_rate)[0]
            centroid_std = np.std(centroid)
            
            # 4. Zero-Crossing Rate ë³€í™”ëŸ‰ (ê·œì¹™ì„±)
            zcr = librosa.feature.zero_crossing_rate(segment)[0]
            zcr_std = np.std(zcr)
            
            # íŒì • ë¡œì§
            reasons = []
            score = 0
            
            # ë¹„í”„ìŒ íŠ¹ì§•: ë§¤ìš° ë‚®ì€ flatness (ìˆœìˆ˜ í†¤)
            if mean_flatness < 0.01:
                reasons.append(f"ìˆœìˆ˜í†¤(flatness={mean_flatness:.4f})")
                score -= 2
            elif mean_flatness < 0.05:
                reasons.append(f"í†¤ì„± ê°•í•¨(flatness={mean_flatness:.4f})")
                score -= 1
            else:
                score += 1
            
            # ë¹„í”„ìŒ íŠ¹ì§•: ì¢ì€ bandwidth
            if mean_bandwidth < 500:
                reasons.append(f"ì¢ì€ì£¼íŒŒìˆ˜(bw={mean_bandwidth:.0f}Hz)")
                score -= 2
            elif mean_bandwidth < 1000:
                score -= 1
            else:
                score += 1
            
            # ë¹„í”„ìŒ íŠ¹ì§•: centroid ë³€í™” ì ìŒ (ì¼ì •í•œ í”¼ì¹˜)
            if centroid_std < 100:
                reasons.append(f"í”¼ì¹˜ë¶ˆë³€(std={centroid_std:.0f})")
                score -= 1
            else:
                score += 1
            
            # ë¹„í”„ìŒ íŠ¹ì§•: zcr ë³€í™” ì ìŒ (ê·œì¹™ì )
            if zcr_std < 0.01:
                reasons.append(f"ê·œì¹™ì (zcr_std={zcr_std:.4f})")
                score -= 1
            else:
                score += 1
            
            # ìµœì¢… íŒì •
            is_voice = score > 0
            reason = ", ".join(reasons) if reasons else "ì •ìƒ ìŒì„±"
            
            return is_voice, reason
        except Exception as e:
            logger.debug(f"Error in _is_human_voice: {e}")
            return True, "ê²€ì‚¬ ì‹¤íŒ¨"
    
    def _is_scream_intensity(self, segment: np.ndarray) -> Tuple[bool, str]:
        """
        ë¹„ëª… ê°•ë„ ë¶„ì„ - ì¼ë°˜ ë§ì†Œë¦¬ì™€ ë¹„ëª…ì„ êµ¬ë¶„ (ì—„ê²©í•œ ê¸°ì¤€)
        
        ë¹„ëª…ì˜ í•µì‹¬ íŠ¹ì§•:
        - ë§¤ìš° ë†’ì€ ì ˆëŒ€ ì—ë„ˆì§€ (í¬ê²Œ ì†Œë¦¬ì¹¨)
        - ì§€ì†ì ì¸ ê³ ì£¼íŒŒ ì—ë„ˆì§€ (ë¹„ëª…ì€ ê³„ì† ë†’ì€ ìŒ)
        - ê¸‰ê²©í•œ onset (ê°‘ìê¸° ì‹œì‘)
        - ë†’ì€ í”¼ì¹˜ (ì¼ë°˜ ë§ì†Œë¦¬ë³´ë‹¤ ë†’ìŒ)
        
        Args:
            segment: ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸
            
        Returns:
            (is_intense, reason) íŠœí”Œ
        """
        if len(segment) < self.sample_rate * 0.1:
            return False, "ë„ˆë¬´ ì§§ìŒ"
        
        # ë¬´ìŒ ì²´í¬ (0 ë‚˜ëˆ„ê¸° ì—ëŸ¬ ë°©ì§€)
        if np.max(np.abs(segment)) < 0.001:
            return False, "ë¬´ìŒ"
        
        try:
            score = 0
            reasons = []
            
            # 1. ì ˆëŒ€ ì—ë„ˆì§€ ìˆ˜ì¤€ (ë¹„ëª…ì€ RMS > 0.05 ì´ìƒ)
            rms = librosa.feature.rms(y=segment)[0]
            mean_rms = np.mean(rms)
            max_rms = np.max(rms)
            
            if mean_rms > 0.08:  # ë§¤ìš° í° ì†Œë¦¬
                score += 2
                reasons.append(f"í°ì†Œë¦¬(rms={mean_rms:.3f})")
            elif mean_rms > 0.05:  # í° ì†Œë¦¬
                score += 1
                reasons.append(f"ì†Œë¦¬í¼(rms={mean_rms:.3f})")
            
            # 2. ì§€ì†ì ì¸ ê³ ì—ë„ˆì§€ (ë¹„ëª…ì€ ê³„ì† í¬ê²Œ)
            # RMSì˜ ìµœì†Œê°’ë„ ë†’ì•„ì•¼ í•¨ (ì ê¹ í° ì†Œë¦¬ê°€ ì•„ë‹ˆë¼ ê³„ì† í° ì†Œë¦¬)
            min_rms = np.min(rms[rms > 0.01]) if np.any(rms > 0.01) else 0
            sustained_ratio = min_rms / (max_rms + 1e-6)
            
            if sustained_ratio > 0.3:  # ì§€ì†ì ìœ¼ë¡œ í° ì†Œë¦¬
                score += 1
                reasons.append(f"ì§€ì†ì ({sustained_ratio:.2f})")
            
            # 3. ê³ ì£¼íŒŒ ì§‘ì¤‘ë„ (ë¹„ëª…ì€ 1000-4000Hzì— ì—ë„ˆì§€ ì§‘ì¤‘)
            stft = np.abs(librosa.stft(segment, n_fft=2048))
            freq_bins = stft.shape[0]
            
            # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€
            low_band = np.mean(stft[:int(freq_bins*0.2), :])   # 0-1600Hz
            mid_band = np.mean(stft[int(freq_bins*0.2):int(freq_bins*0.5), :])  # 1600-4000Hz (ë¹„ëª… ëŒ€ì—­)
            high_band = np.mean(stft[int(freq_bins*0.5):, :])  # 4000Hz+
            
            # ë¹„ëª… ëŒ€ì—­ ë¹„ìœ¨
            scream_band_ratio = mid_band / (low_band + high_band + 1e-6)
            
            if scream_band_ratio > 1.5:  # ë¹„ëª… ëŒ€ì—­ì— ì—ë„ˆì§€ ì§‘ì¤‘
                score += 2
                reasons.append(f"ë¹„ëª…ëŒ€ì—­({scream_band_ratio:.2f})")
            elif scream_band_ratio > 1.0:
                score += 1
                reasons.append(f"ì¤‘ê³ ì£¼íŒŒ({scream_band_ratio:.2f})")
            
            # 4. ë†’ì€ í‰ê·  í”¼ì¹˜ (ë¹„ëª…ì€ ë³´í†µ 500Hz ì´ìƒ)
            pitches, magnitudes = librosa.piptrack(y=segment, sr=self.sample_rate, fmin=100, fmax=4000)
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 100:  # ìœ íš¨í•œ í”¼ì¹˜ë§Œ
                    pitch_values.append(pitch)
            
            if len(pitch_values) > 5:
                mean_pitch = np.mean(pitch_values)
                if mean_pitch > 600:  # ë§¤ìš° ë†’ì€ í”¼ì¹˜
                    score += 2
                    reasons.append(f"ê³ í”¼ì¹˜({mean_pitch:.0f}Hz)")
                elif mean_pitch > 400:  # ë†’ì€ í”¼ì¹˜
                    score += 1
                    reasons.append(f"í”¼ì¹˜ë†’ìŒ({mean_pitch:.0f}Hz)")
            
            # 5. Spectral Rolloff (ë¹„ëª…ì€ ì—ë„ˆì§€ê°€ ê³ ì£¼íŒŒê¹Œì§€ ë¶„í¬)
            rolloff = librosa.feature.spectral_rolloff(y=segment, sr=self.sample_rate, roll_percent=0.85)[0]
            mean_rolloff = np.mean(rolloff)
            
            if mean_rolloff > 4000:  # ì—ë„ˆì§€ê°€ 4000Hz ì´ìƒê¹Œì§€ ë¶„í¬
                score += 1
                reasons.append(f"ë¡¤ì˜¤í”„({mean_rolloff:.0f}Hz)")
            
            # ìµœì¢… íŒì •: 5ì  ì´ìƒì´ì–´ì•¼ ë¹„ëª… (ë” ì—„ê²©)
            # ìµœëŒ€ ê°€ëŠ¥ ì ìˆ˜: 2+1+2+2+1 = 8ì 
            is_intense = score >= 5
            reason = ", ".join(reasons) if reasons else "ì¼ë°˜ ìŒì„±"
            
            return is_intense, reason
        except Exception as e:
            logger.debug(f"Error in _is_scream_intensity: {e}")
            return False, "ê²€ì‚¬ ì‹¤íŒ¨"

    def predict(self, audio_data: np.ndarray, sr: Optional[int] = None) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°›ì•„ ë¹„ëª… ì—¬ë¶€ íŒì • (ìƒì„¸í•œ ê²°ê³¼ ë°˜í™˜)
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ë‹¤ë¥¼ ê²½ìš° 16000ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§ë¨)
            
        Returns:
            dict: {
                "is_scream": bool,  # ìµœì¢… ë¹„ëª… íŒì •
                "prob": float,      # ëª¨ë¸ í™•ë¥  (0.0 ~ 1.0)
                "status": str,      # "SCREAM", "SAFE", "SPEECH", "FILTERED"
                "reason": str       # íŒì • ì´ìœ 
            }
        """
        # ë¦¬ìƒ˜í”Œë§
        if sr and sr != self.sample_rate:
            try:
                audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=self.sample_rate)
            except Exception as e:
                logger.warning(f"Resampling failed: {e}, using original audio")
        
        # 0. ë¬´ìŒ(Silence) ì²´í¬ 0 ë‚˜ëˆ„ê¸° ì—ëŸ¬ ë°©ì§€
        # ì•„ì£¼ ì‘ì€ ì†Œë¦¬ëŠ” ì•„ì˜ˆ ê³„ì‚° ì•ˆ í•¨ (GPU ì „ì†¡ ì „ì— ì°¨ë‹¨)
        max_amplitude = np.max(np.abs(audio_data)) if len(audio_data) > 0 else 0.0
        if max_amplitude < 0.001:
            logger.warning(f"ë¬´ìŒ í•„í„°ë§: max_amplitude={max_amplitude:.6f} (ë„ˆë¬´ ë‚®ìŒ)")
            return {
                "is_scream": False,
                "prob": 0.0,
                "status": "FILTERED",
                "reason": "ë¬´ìŒ(Silence)",
                "confidence": 0.0,
                "threshold": self.threshold
            }
        
        # 1. ê¸°ê³„ìŒ í•„í„°ë§ (í™œì„±í™”ëœ ê²½ìš°) - ì›ë³¸ê³¼ ë™ì¼: í•„í„°ë§ë˜ì–´ë„ ëª¨ë¸ ì¶”ë¡ ì€ ì‹¤í–‰
        filtered_by_voice = False
        voice_reason = ""
        if self.enable_filtering:
            is_human, voice_reason = self._is_human_voice(audio_data)
            if not is_human:
                filtered_by_voice = True
                logger.warning(f"ê¸°ê³„ìŒ í•„í„°ë§: {voice_reason}")
                # ì›ë³¸ ì½”ë“œëŠ” í•„í„°ë§ë˜ì–´ë„ probëŠ” ë°˜í™˜í•˜ì§€ë§Œ, is_screamì€ False
                # ì—¬ê¸°ì„œëŠ” ëª¨ë¸ ì¶”ë¡ ì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ë°˜í™˜ (ì›ë³¸ê³¼ ì•½ê°„ ë‹¤ë¦„)
                return {
                    "is_scream": False,
                    "prob": 0.0,  # ì›ë³¸ë„ í•„í„°ë§ ì‹œ prob=0.0 ë°˜í™˜
                    "status": "FILTERED",
                    "reason": f"ê¸°ê³„ìŒ ê°ì§€ ({voice_reason})",
                    "confidence": 0.0,
                    "threshold": self.threshold
                }
        
        # 2. ëª¨ë¸ ì¶”ë¡  (ì›ë³¸ê³¼ ë™ì¼)
        try:
            feature = self._preprocess(audio_data)
            with torch.no_grad():
                outputs = self.model(feature)
                probabilities = F.softmax(outputs, dim=1)
                prob_scream = probabilities[0][1].item()
                logger.warning(f"ğŸ¤– ëª¨ë¸ ì¶”ë¡  ê²°ê³¼: prob_scream={prob_scream:.4f}, threshold={self.threshold}, is_scream={prob_scream > self.threshold}")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬: ì¶”ë¡  í›„ í…ì„œë¥¼ CPUë¡œ ì´ë™ í›„ ì‚­ì œ (ë” í™•ì‹¤í•œ ì •ë¦¬)
            if self.device == "cuda":
                # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
                torch.cuda.synchronize()
                # í…ì„œë¥¼ CPUë¡œ ì´ë™ í›„ ì‚­ì œ (GPU ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ)
                if feature.is_cuda:
                    feature = feature.cpu()
                if outputs.is_cuda:
                    outputs = outputs.cpu()
                if probabilities.is_cuda:
                    probabilities = probabilities.cpu()
                del feature, outputs, probabilities
                # Python ê°€ë¹„ì§€ ì»¬ë ‰í„°ë„ í˜¸ì¶œ
                gc.collect()
                # GPU ìºì‹œ ì •ë¦¬
                torch.cuda.empty_cache()
        except Exception as e:
            logger.error(f"Model inference error: {e}", exc_info=True)
            return {
                "is_scream": False,
                "prob": 0.0,
                "status": "SAFE",
                "reason": f"ì¶”ë¡  ì˜¤ë¥˜: {str(e)}",
                "confidence": 0.0,
                "threshold": self.threshold
            }
        
        # 3. ë¹„ëª… ê°•ë„ í•„í„°ë§ (ì›ë³¸ê³¼ ë™ì¼: prob_scream > THRESHOLDì¼ ë•Œë§Œ ì²´í¬)
        final_is_scream = prob_scream > self.threshold
        intensity_reason = ""
        
        if self.enable_filtering and prob_scream > self.threshold:
            is_intense, intensity_reason = self._is_scream_intensity(audio_data)
            if not is_intense:
                final_is_scream = False  # ì›ë³¸: final_is_scream = False
        
        # ì›ë³¸ê³¼ ë™ì¼: probëŠ” í•­ìƒ ë°˜í™˜, is_screamë§Œ í•„í„°ë§ìœ¼ë¡œ ê²°ì •
        status = "SCREAM" if final_is_scream else "SAFE"
        
        return {
            "is_scream": final_is_scream,
            "prob": prob_scream,  # ì›ë³¸ê³¼ ë™ì¼: í•„í„°ë§ë˜ì–´ë„ ì‹¤ì œ ëª¨ë¸ í™•ë¥  ë°˜í™˜
            "status": status,
            "reason": intensity_reason if intensity_reason else "ì •ìƒ",
            "confidence": prob_scream,
            "threshold": self.threshold
        }
    
    def detect(self, audio: np.ndarray, sr: Optional[int] = None) -> Tuple[bool, float]:
        """
        ì˜¤ë””ì˜¤ì—ì„œ ë¹„ëª… ê°ì§€ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
        
        Args:
            audio: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array, float32, [-1, 1] ë²”ìœ„)
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            (is_scream, confidence) íŠœí”Œ
            
        Note:
            ìµœì†Œ ì˜¤ë””ì˜¤ ê¸¸ì´: ì•½ 0.1ì´ˆ (1600 ìƒ˜í”Œ @ 16kHz)
            ê¶Œì¥ ì˜¤ë””ì˜¤ ê¸¸ì´: 2.0ì´ˆ (32000 ìƒ˜í”Œ @ 16kHz)
        """
        result = self.predict(audio, sr=sr)
        return result["is_scream"], result["prob"]

    def process(self, audio_data: np.ndarray, sr: Optional[int] = None) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ (AudioProcessor ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return self.predict(audio_data, sr=sr)
